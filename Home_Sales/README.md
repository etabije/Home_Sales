# Home_Sales

Module 22 Challenge

This project focuses on working with large datasets using Apache Spark to analyze home sales data. The goal is to apply SQL and DataFrame operations to gain insights from the dataset stored in various formats, such as CSV and Parquet, while utilizing the power of Spark's distributed computing.

The tasks include reading data from an S3 bucket, transforming the data, creating temporary views, and performing various SQL queries to calculate average home prices based on specific conditions, such as the number of bedrooms, bathrooms, and square footage. Additionally, the project demonstrates performance optimization techniques, including caching and partitioning data for faster queries.

By the end of this challenge, the user gains hands-on experience with SparkSQL, including the use of Spark's powerful features like caching, partitioning, and managing data in formats like Parquet, enabling efficient data analysis at scale.

Resources:
Professor Melissa Ingle
Cassidy Cruz (classmate)
ChatGPT
Xpert Learning Assistant